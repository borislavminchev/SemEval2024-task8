{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95460,"status":"ok","timestamp":1751568644703,"user":{"displayName":"Angel Kirilov","userId":"16100377354124465662"},"user_tz":-180},"id":"FrX2IZXfwGvu","outputId":"fb9d846c-d124-4455-f351-35b090fbfbdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Collecting evaluate\n","  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n","Collecting emoji\n","  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Downloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed emoji-2.14.1 evaluate-0.4.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}],"source":["!pip install datasets pandas evaluate numpy transformers scipy scikit-learn accelerate emoji"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":965,"referenced_widgets":["b2d89dd4c0c149e9b4b7520563656550","068edb49a5fa46ae8c82f08408e603da","042461ee284942b78ecedf7cbd9950fe","379e866364044e36aedc49cd2e5db884","1a97d49a7b734f21bb0581794569e70e","100156ecaffc4346993de0b6dbbbfa86","f6aa16f3e3674e37a4eb010d90847828","d7cc87b0a4d941ec8e93f90e6172a606","c3d72a33cb2240f1b1f52072422fb67c","386730f5721c4e4194808b195ef6ac65","727c74ab9daf430a80d42fc196a27f3b","aef50d144c3d49af97f6eba427500a12","950c6d960daa4272b559391eefaacbc3","07c29ba0ff7f4587827c249f2dfbd635","5190df24fcdc4232874a3a4114cdd73a","257e65ae830f43b3aba876bd3a3da570","a62488b01d1041398361b8fbd131ac28","cee86f4c70f547cda2b4d0212d7fc1e5","a46d2baef4bb4597a55a49f30e03a4fc","5e85122f8cce466489e23602579c8286","b74e1c36f4e7493b936176949cac092c","dd026b5dfbef4c07b47ba9efafd696d1","4cfb353b11dd4bfe93e6204e17be5e75","ed7db3bb80a045118d9bfe099bf22982","fbc1f4cf70b44cb9ba1b34d6854aa7bb","d46b5af37e7942e082e2fbe0118d160a","ea8c5fc2dcce4eb39a1f34d2440e976c","a9c0a5ef92f04245a445cf695c3262d6","8e650e49ef424cc8997a1def75e61064","f774e2cca2844ed3bde6e6536e8fe8a8","d4f7ccae865a4b5ca2b4808b70fdfc1c","0c4cda6112cc4206887e586ae828551b","0f116f156a4f4e98801a1a4d1c89d875","05e39a0110884203b8d69f878a55370a","a102d587e4ab4e6281b6e909318af061","65d01be201d04575a83280df71d98ff6","e215d7b16d8345a58c153d605bb04467","53fa0a7be32e44a28a3e262c84aae5e3","64cacccb03f34641a837395ac5647334","524501b2f23c4cf7b079eaa0598248aa","a92e5c9f40f84b4581913f900bdcea3c","f0a81f971e494574a08f7244e48f9c39","9d16894fc717460d9e983db7d70561d7","b3d179eead9441c6a1a318e8f44deb8b","07cd1102e81e499abbb339907b19fefd","207424f0a86d4ae7af66d8eef02b3287","abfc6339a3144d74bc012e44d7568205","c5f798af68e94730a486220ffe51203a","7ee391a293a349a9b8d8589b4660f982","29cb3b2cfa914f5399183f62331e372d","c20884050fdf40ea951e6548cf931440","d96e1ab45cd941dd826e967713660dae","f8a62e8e72b04f07aeb55f95e04a9b00","b57308f8370e4db4967d974bcef4c55d","67782482f5284cbe80a05c9e832da44d","6364e5a4cbc64ae794b54d572e934689","903e68f3ea744fefa2352b3b5ac25a41","14a5282ff77c41298149548c1528cdce","4b768c23c8064b89801995b897991db5","60eb848f970243a8bf2a5c3add4a4116","2483fb0927bc4471b7462cb9d3661ffd","d102f7de16174886a351a96a8b0e16b1","e3b3b49c1c6845318e1b9fee1b0163d5","87ae35cdf89d4cb39fae63597dfad6cb","679aff465a2a4801863e61e015df1e9c","14784ec1eb4e42a9b76dbd95315a42ac"]},"id":"j_ovY2JqwBOB","outputId":"5f151278-a408-40c5-d421-ba7271fb4e1b","executionInfo":{"status":"ok","timestamp":1751576856326,"user_tz":-180,"elapsed":7343328,"user":{"displayName":"Angel Kirilov","userId":"16100377354124465662"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Class distribution in training data:\n","label\n","0    11997\n","1    11995\n","2    11336\n","3    11999\n","4    11998\n","5    11702\n","Name: count, dtype: int64\n","Training samples: 60372\n","Validation samples: 10655\n","Test samples: 18000\n","total layers: 12\n","Frozen 213,662,208 parameters\n","Trainable 64,381,440 parameters (23.2%)\n","Frozen 3 transformer layers + embeddings\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/60372 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2d89dd4c0c149e9b4b7520563656550"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/10655 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef50d144c3d49af97f6eba427500a12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='18870' max='18870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [18870/18870 1:54:47, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.133100</td>\n","      <td>0.201413</td>\n","      <td>0.861380</td>\n","      <td>0.861380</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.087200</td>\n","      <td>0.165754</td>\n","      <td>0.892257</td>\n","      <td>0.892257</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.059100</td>\n","      <td>0.225496</td>\n","      <td>0.889348</td>\n","      <td>0.889348</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.023200</td>\n","      <td>0.317322</td>\n","      <td>0.881276</td>\n","      <td>0.881276</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.026500</td>\n","      <td>0.410663</td>\n","      <td>0.868512</td>\n","      <td>0.868512</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cfb353b11dd4bfe93e6204e17be5e75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e39a0110884203b8d69f878a55370a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of XLMRobertaModel were not initialized from the model checkpoint at ./checkpoints/xlm-roberta-base_custom_classifier/best and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/18000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07cd1102e81e499abbb339907b19fefd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6364e5a4cbc64ae794b54d572e934689"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["=== Classification Report ===\n","0: {'precision': 0.9960199004975124, 'recall': 0.33366666666666667, 'f1-score': 0.4998751560549313, 'support': 3000.0}\n","1: {'precision': 0.4207104345068189, 'recall': 0.8843333333333333, 'f1-score': 0.5701697829357404, 'support': 3000.0}\n","2: {'precision': 0.0851063829787234, 'recall': 0.008, 'f1-score': 0.014625228519195612, 'support': 3000.0}\n","3: {'precision': 0.49916072177926984, 'recall': 0.793, 'f1-score': 0.6126706155034767, 'support': 3000.0}\n","4: {'precision': 0.9963406520292748, 'recall': 0.9983333333333333, 'f1-score': 0.9973359973359973, 'support': 3000.0}\n","5: {'precision': 0.47210626185958254, 'recall': 0.4146666666666667, 'f1-score': 0.4415261756876664, 'support': 3000.0}\n","accuracy: 0.572\n","macro avg: {'precision': 0.5782407256085303, 'recall': 0.572, 'f1-score': 0.5227004926728346, 'support': 18000.0}\n","weighted avg: {'precision': 0.5782407256085302, 'recall': 0.572, 'f1-score': 0.5227004926728345, 'support': 18000.0}\n","Done. Predictions saved to ./subtaskB_predictions.jsonl\n"]}],"source":["import os\n","import argparse\n","import logging\n","import re\n","import emoji\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","from scipy.special import softmax\n","import evaluate\n","\n","from transformers.models.auto.modeling_auto import AutoModel\n","from transformers.models.auto.tokenization_auto import AutoTokenizer\n","from transformers.models.auto.configuration_auto import AutoConfig\n","from transformers.data.data_collator import DataCollatorWithPadding\n","from transformers.training_args import TrainingArguments\n","from transformers.trainer import Trainer\n","from transformers.trainer_utils import set_seed\n","from transformers.trainer_callback import EarlyStoppingCallback\n","from transformers import PreTrainedModel\n","from transformers.modeling_outputs import SequenceClassifierOutput\n","\n","\n","class CustomClassifierHead(nn.Module):\n","    def __init__(self, hidden_size: int, num_labels: int, dropout_rate: float = 0.4):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(hidden_size)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc = nn.Linear(hidden_size, hidden_size // 2)\n","        self.act = nn.GELU()\n","        self.out = nn.Linear(hidden_size // 2, num_labels)\n","\n","    def forward(self, hidden_states):\n","        x = self.norm(hidden_states)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        x = self.act(x)\n","        x = self.dropout(x)\n","        return self.out(x)\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma: float = 2.0, weight: torch.Tensor = None):\n","        super().__init__()\n","        self.gamma = gamma\n","        self.ce = nn.CrossEntropyLoss(weight=weight, reduction=\"none\")\n","\n","    def forward(self, logits, labels):\n","        logp = -self.ce(logits, labels)            # –CE\n","        p    = logp.exp()                          # prob of true class\n","        loss = -(1 - p)**self.gamma * logp         # focal term\n","        return loss.mean()\n","\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, gamma: float = 2.0, weight: torch.Tensor = None):\n","        super().__init__()\n","        self.gamma = gamma\n","        self.weight = weight  # Class weights tensor\n","\n","    def forward(self, logits, labels):\n","        log_softmax = F.log_softmax(logits, dim=-1)\n","\n","        logpt = log_softmax[range(len(labels)), labels]\n","        pt = logpt.exp()\n","\n","        if self.weight is not None:\n","            weight = self.weight[labels]\n","        else:\n","            weight = 1.0\n","\n","        focal_term = (1 - pt) ** self.gamma\n","        ce_term = -logpt\n","\n","        loss_per_sample = weight * focal_term * ce_term\n","\n","        return loss_per_sample.mean()\n","\n","\n","class TransformerWithCustomClassifier(PreTrainedModel):\n","    \"\"\"\n","    Transformer model with frozen backbone and custom classifier head\n","    \"\"\"\n","    # Add config_class attribute - this is crucial for from_pretrained to work\n","    config_class = AutoConfig\n","\n","    def __init__(self, config, model_name: str = None, num_labels: int = None, freeze_layers: int = 6):\n","        super().__init__(config)\n","\n","        # Handle both initialization scenarios\n","        if model_name is not None:\n","            # Direct initialization with model_name\n","            self.transformer = AutoModel.from_pretrained(model_name)\n","            self.num_labels = num_labels or config.num_labels\n","        else:\n","            # Loading from pretrained - we need the original model name stored in config\n","            if hasattr(config, '_name_or_path') and config._name_or_path:\n","                # Try to get the original model name from config\n","                original_model_name = config._name_or_path\n","                try:\n","                    self.transformer = AutoModel.from_pretrained(original_model_name)\n","                except:\n","                    # Fallback to creating from config\n","                    self.transformer = AutoModel.from_config(config)\n","            else:\n","                # Fallback to creating from config\n","                self.transformer = AutoModel.from_config(config)\n","            self.num_labels = config.num_labels\n","\n","        self.config = config\n","\n","        # Freeze specified number of layers (only during training initialization)\n","        if model_name is not None:\n","            self.freeze_transformer_layers(freeze_layers)\n","\n","        # Custom classifier head\n","        hidden_size = self.transformer.config.hidden_size\n","        self.classifier = CustomClassifierHead(\n","            hidden_size=hidden_size,\n","            num_labels=self.num_labels,\n","            dropout_rate=0.4\n","        )\n","\n","        # Initialize weights\n","        self.post_init()\n","\n","    @classmethod\n","    def from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs):\n","        \"\"\"\n","        Override from_pretrained to handle our custom model properly\n","        \"\"\"\n","        # Load config first\n","        config = AutoConfig.from_pretrained(pretrained_model_name_or_path, **kwargs)\n","\n","        # Create model instance without model_name (loading scenario)\n","        model = cls(config, model_name=None)\n","\n","        # Try different file formats\n","        model_file = None\n","        possible_files = [\n","            \"pytorch_model.bin\",\n","            \"model.safetensors\",\n","            \"pytorch_model.safetensors\"\n","        ]\n","\n","        for filename in possible_files:\n","            filepath = os.path.join(pretrained_model_name_or_path, filename)\n","            if os.path.exists(filepath):\n","                model_file = filepath\n","                break\n","\n","        if model_file is None:\n","            raise FileNotFoundError(f\"No model file found in {pretrained_model_name_or_path}\")\n","\n","        # Load state dict based on file type\n","        if model_file.endswith('.safetensors'):\n","            from safetensors.torch import load_file\n","            state_dict = load_file(model_file)\n","        else:\n","            state_dict = torch.load(model_file, map_location=\"cpu\")\n","\n","        # Load the state dict into the model\n","        missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n","\n","        if missing_keys:\n","            print(f\"Warning: Missing keys when loading model: {missing_keys}\")\n","        if unexpected_keys:\n","            print(f\"Warning: Unexpected keys when loading model: {unexpected_keys}\")\n","\n","        return model\n","\n","    def freeze_transformer_layers(self, num_layers_to_freeze: int):\n","        \"\"\"\n","        Freeze bottom N transformer layers and embeddings\n","        Works with different transformer architectures (BERT, RoBERTa, XLM-RoBERTa, etc.)\n","        \"\"\"\n","        frozen_params = 0\n","        total_params = 0\n","\n","        # Freeze embeddings - handle different architectures\n","        if hasattr(self.transformer, 'embeddings'):\n","            for param in self.transformer.embeddings.parameters():\n","                param.requires_grad = False\n","                frozen_params += param.numel()\n","\n","        # Freeze specified number of encoder layers - handle different architectures\n","        encoder_layers = None\n","        if hasattr(self.transformer, 'encoder') and hasattr(self.transformer.encoder, 'layer'):\n","            encoder_layers = self.transformer.encoder.layer\n","        elif hasattr(self.transformer, 'encoder') and hasattr(self.transformer.encoder, 'layers'):\n","            encoder_layers = self.transformer.encoder.layers\n","        elif hasattr(self.transformer, 'layers'):\n","            encoder_layers = self.transformer.layers\n","\n","        if encoder_layers is not None:\n","            print(f\"total layers: {len(encoder_layers)}\")\n","            num_to_freeze = min(num_layers_to_freeze, len(encoder_layers))\n","\n","            for i in range(num_to_freeze):\n","                for param in encoder_layers[i].parameters():\n","                    param.requires_grad = False\n","                    frozen_params += param.numel()\n","        else:\n","            print(\"Warning: Could not find encoder layers to freeze\")\n","            num_to_freeze = 0\n","\n","        # Count total parameters\n","        for param in self.parameters():\n","            total_params += param.numel()\n","\n","        trainable_params = total_params - frozen_params\n","        print(f\"Frozen {frozen_params:,} parameters\")\n","        print(f\"Trainable {trainable_params:,} parameters ({100*trainable_params/total_params:.1f}%)\")\n","        print(f\"Frozen {num_to_freeze} transformer layers + embeddings\")\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n","        \"\"\"\n","        Forward pass through transformer + custom classifier\n","        \"\"\"\n","        # Filter kwargs to only include valid transformer arguments\n","        valid_kwargs = {}\n","        transformer_forward_keys = [\n","            'token_type_ids', 'position_ids', 'head_mask', 'inputs_embeds',\n","            'encoder_hidden_states', 'encoder_attention_mask',\n","            'output_attentions', 'output_hidden_states', 'return_dict'\n","        ]\n","\n","        for key in transformer_forward_keys:\n","            if key in kwargs:\n","                valid_kwargs[key] = kwargs[key]\n","\n","        # Get transformer outputs\n","        transformer_outputs = self.transformer(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            **valid_kwargs\n","        )\n","\n","        # Use [CLS] token representation (first token)\n","        pooled_output = transformer_outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n","\n","        # Pass through custom classifier\n","        logits = self.classifier(pooled_output)\n","\n","        loss = None\n","\n","        if labels is not None:\n","          loss_fn = FocalLoss(gamma=2.0)  # Pass weights here\n","          loss = loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n","\n","        return SequenceClassifierOutput(\n","            loss=loss,\n","            logits=logits,\n","            hidden_states=transformer_outputs.hidden_states,\n","            attentions=transformer_outputs.attentions,\n","        )\n","\n","\n","class AlternativeCustomClassifier(nn.Module):\n","    \"\"\"\n","    Alternative classifier design with attention pooling\n","    \"\"\"\n","    def __init__(self, hidden_size: int, num_labels: int, dropout_rate: float = 0.3):\n","        super().__init__()\n","\n","        # Attention pooling layer\n","        self.attention = nn.MultiheadAttention(\n","            embed_dim=hidden_size,\n","            num_heads=8,\n","            dropout=dropout_rate,\n","            batch_first=True\n","        )\n","\n","        # Classification layers\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.layer_norm = nn.LayerNorm(hidden_size)\n","\n","        # Deep classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(hidden_size, hidden_size),\n","            nn.LayerNorm(hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","\n","            nn.Linear(hidden_size, hidden_size // 2),\n","            nn.LayerNorm(hidden_size // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout_rate),\n","\n","            nn.Linear(hidden_size // 2, num_labels)\n","        )\n","\n","    def forward(self, hidden_states, attention_mask=None):\n","        # Apply attention pooling across sequence length\n","        attended_output, _ = self.attention(hidden_states, hidden_states, hidden_states)\n","\n","        # Mean pooling with attention mask\n","        if attention_mask is not None:\n","            mask_expanded = attention_mask.unsqueeze(-1).expand(attended_output.size()).float()\n","            sum_embeddings = torch.sum(attended_output * mask_expanded, 1)\n","            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n","            pooled_output = sum_embeddings / sum_mask\n","        else:\n","            pooled_output = attended_output.mean(dim=1)\n","\n","        # Apply layer norm and dropout\n","        pooled_output = self.layer_norm(pooled_output)\n","        pooled_output = self.dropout(pooled_output)\n","\n","        # Classification\n","        logits = self.classifier(pooled_output)\n","        return logits\n","\n","\n","def clean_text(text: str) -> str:\n","    \"\"\"\n","    SIMPLIFIED text cleaning - preserve more linguistic features\n","    \"\"\"\n","    # Keep original case - it might be important for AI detection\n","    # text = text.lower()  # REMOVED\n","\n","    # Replace URLs but keep them as tokens\n","    text = re.sub(r'https?://\\S+', ' [URL] ', text)\n","\n","    # Remove HTML tags\n","    text = re.sub(r'<[^>]+>', ' ', text)\n","\n","    # Keep @mentions and #hashtags - they might be stylistic indicators\n","    # text = re.sub(r'@\\w+|#\\w+', ' ', text)  # REMOVED\n","\n","    # Convert emojis to text (keep this - emotional expression matters)\n","    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n","\n","    # MUCH less aggressive character filtering - keep punctuation patterns\n","    text = re.sub(r'[^\\w\\s@#.,!?;:()\\[\\]{}\"\\'-]', ' ', text)\n","\n","    # Collapse multiple spaces\n","    text = \" \".join(text.split()).strip()\n","    return text if text else \"[BLANK]\"\n","\n","\n","def preprocess_function(examples, tokenizer, max_length: int = 512):\n","    \"\"\"\n","    Tokenize texts, truncating/padding to max_length.\n","    \"\"\"\n","    return tokenizer(\n","        examples[\"text\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_length,\n","    )\n","\n","\n","def get_data(train_path: str, test_path: str, random_seed: int):\n","    \"\"\"\n","    Load and prepare data with minimal preprocessing\n","    \"\"\"\n","    train_df = pd.read_json(train_path, lines=True)\n","    test_df = pd.read_json(test_path, lines=True)\n","\n","    # Clean text (less aggressively now)\n","    train_df[\"text\"] = train_df[\"text\"].map(clean_text)\n","    test_df[\"text\"] = test_df[\"text\"].map(clean_text)\n","\n","    # Check class distribution\n","    print(\"Class distribution in training data:\")\n","    print(train_df[\"label\"].value_counts().sort_index())\n","\n","    # Stratified split: 85% train / 15% dev (more training data)\n","    train_df, val_df = train_test_split(\n","        train_df,\n","        test_size=0.15,  # Reduced validation size\n","        stratify=train_df[\"label\"],\n","        random_state=random_seed,\n","    )\n","    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)\n","\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"\n","    Compute both accuracy and micro-F1\n","    \"\"\"\n","    accuracy_metric = evaluate.load(\"accuracy\")\n","    f1_metric = evaluate.load(\"f1\")\n","\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=1)\n","\n","    accuracy = accuracy_metric.compute(predictions=preds, references=labels)\n","    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"micro\")\n","\n","    return {\"accuracy\": accuracy[\"accuracy\"], \"f1\": f1[\"f1\"]}\n","\n","\n","def fine_tune(\n","    train_df: pd.DataFrame,\n","    valid_df: pd.DataFrame,\n","    output_dir: str,\n","    id2label: dict,\n","    label2id: dict,\n","    model_name: str,\n","    device: torch.device,\n","    num_epochs: int = 5,\n","    per_device_batch: int = 16,\n","    gradient_accumulation_steps: int = 1,\n","    max_length: int = 512,\n","    freeze_layers: int = 6,  # NEW: Number of layers to freeze\n","    use_custom_classifier: bool = True,  # NEW: Whether to use custom classifier\n","):\n","    \"\"\"\n","    Fine-tune with frozen layers and custom classifier\n","    \"\"\"\n","    # Convert to HF Datasets\n","    train_ds = Dataset.from_pandas(train_df)\n","    valid_ds = Dataset.from_pandas(valid_df)\n","\n","    # Load tokenizer\n","    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","    # Load model with custom classifier and frozen layers\n","    if use_custom_classifier:\n","        # Create a config for our custom model\n","        base_model = AutoModel.from_pretrained(model_name)\n","        config = base_model.config\n","        config.num_labels = len(label2id)\n","        config.id2label = id2label\n","        config.label2id = label2id\n","\n","        model = TransformerWithCustomClassifier(\n","            config=config,\n","            model_name=model_name,\n","            num_labels=len(label2id),\n","            freeze_layers=freeze_layers\n","        )\n","    else:\n","        # Use standard approach (for comparison)\n","        from transformers.models.auto.modeling_auto import AutoModelForSequenceClassification\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_name,\n","            num_labels=len(label2id),\n","            id2label=id2label,\n","            label2id=label2id,\n","        )\n","\n","    model.config.pad_token_id = tokenizer.pad_token_id\n","    model.to(device)\n","\n","    # Tokenize dataset\n","    tokenized_train = train_ds.map(\n","        lambda ex: preprocess_function(ex, tokenizer, max_length),\n","        batched=True,\n","        remove_columns=[\"text\"],\n","    )\n","    tokenized_valid = valid_ds.map(\n","        lambda ex: preprocess_function(ex, tokenizer, max_length),\n","        batched=True,\n","        remove_columns=[\"text\"],\n","    )\n","\n","    data_collator = DataCollatorWithPadding(tokenizer)\n","\n","    # Training arguments - optimized for frozen layers\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        eval_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        learning_rate=3e-5,  # Slightly higher LR for custom classifier\n","        lr_scheduler_type=\"cosine\",\n","        per_device_train_batch_size=per_device_batch,  # Can use larger batch with frozen layers\n","        per_device_eval_batch_size=per_device_batch,\n","        gradient_accumulation_steps=gradient_accumulation_steps,\n","        num_train_epochs=num_epochs,\n","        weight_decay=0.03,\n","        warmup_ratio=0.1,\n","        # fp16=True,  # Enable mixed precision\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"eval_f1\",\n","        greater_is_better=True,\n","        eval_accumulation_steps=1,\n","        dataloader_num_workers=2,\n","        logging_steps=25,\n","        logging_dir=os.path.join(output_dir, \"logs\"),\n","        remove_unused_columns=True,  # Important for avoiding argument errors\n","    )\n","\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        learning_rate=3e-5,\n","        lr_scheduler_type=\"cosine\",\n","        per_device_train_batch_size=per_device_batch,\n","        per_device_eval_batch_size=per_device_batch,\n","        num_train_epochs=num_epochs,\n","        weight_decay=0.01,\n","        fp16=True,\n","        eval_strategy=\"epoch\",\n","        save_strategy=\"epoch\",\n","        logging_steps=25,\n","        logging_dir=os.path.join(output_dir, \"logs\"),\n","        load_best_model_at_end=True,\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=tokenized_train,\n","        eval_dataset=tokenized_valid,\n","        processing_class=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n","    )\n","\n","    # Start training\n","    trainer.train()\n","\n","    # Save the best model\n","    best_dir = os.path.join(output_dir, \"best\")\n","    os.makedirs(best_dir, exist_ok=True)\n","    trainer.save_model(best_dir)\n","\n","\n","def test(\n","    test_df: pd.DataFrame,\n","    model_path: str,\n","    id2label: dict,\n","    label2id: dict,\n","    device: torch.device,\n","    max_length: int = 512,\n","    use_custom_classifier: bool = True,\n","):\n","    \"\"\"\n","    Run inference on the test set\n","    \"\"\"\n","    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","    if use_custom_classifier:\n","        # Load custom model using our custom from_pretrained method\n","        model = TransformerWithCustomClassifier.from_pretrained(model_path)\n","    else:\n","        from transformers.models.auto.modeling_auto import AutoModelForSequenceClassification\n","        model = AutoModelForSequenceClassification.from_pretrained(\n","            model_path,\n","            num_labels=len(label2id),\n","            id2label=id2label,\n","            label2id=label2id,\n","        )\n","\n","    model.config.pad_token_id = tokenizer.pad_token_id\n","    model.to(device)\n","\n","    test_ds = Dataset.from_pandas(test_df)\n","    tokenized_test = test_ds.map(\n","        lambda ex: preprocess_function(ex, tokenizer, max_length),\n","        batched=True,\n","        remove_columns=[\"text\"],\n","    )\n","\n","    data_collator = DataCollatorWithPadding(tokenizer)\n","    trainer = Trainer(\n","        model=model,\n","        processing_class=tokenizer,\n","        data_collator=data_collator,\n","        compute_metrics=compute_metrics,\n","    )\n","\n","    predictions_output = trainer.predict(tokenized_test)\n","    logits = predictions_output.predictions\n","    probs = softmax(logits, axis=-1)\n","    preds = np.argmax(probs, axis=1)\n","\n","    # Compute results if labels exist\n","    if predictions_output.label_ids is not None:\n","        report = evaluate.load(\"bstrai/classification_report\")\n","        results = report.compute(\n","            predictions=preds, references=predictions_output.label_ids\n","        )\n","    else:\n","        results = None\n","\n","    return results, preds\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser(description=\"Transformer fine-tuning with custom classifier and layer freezing\")\n","    parser.add_argument(\"--train_file_path\", \"-tr\", required=False, default='./subtaskB_train.jsonl', help=\"Path to the train JSONL file\", type=str)\n","    parser.add_argument(\"--test_file_path\", \"-t\", required=False, default='./subtaskB.jsonl', help=\"Path to the test JSONL file\", type=str)\n","    parser.add_argument(\"--model\", \"-m\", required=False, default=\"xlm-roberta-base\", help=\"HuggingFace model name\", type=str)\n","    parser.add_argument(\"--output_dir\", \"-o\", required=False, default=\"./checkpoints\", help=\"Directory to save checkpoints\", type=str)\n","    parser.add_argument(\"--prediction_file_path\", \"-p\", required=False, default=\"./subtaskB_predictions.jsonl\", help=\"Where to save predictions\", type=str)\n","    parser.add_argument(\"--num_epochs\", \"-e\", required=False, default=5, help=\"Number of training epochs\", type=int)\n","    parser.add_argument(\"--batch_size\", \"-b\", required=False, default=16, help=\"Per-device batch size\", type=int)\n","    parser.add_argument(\"--accum_steps\", \"-a\", required=False, default=1, help=\"Gradient accumulation steps\", type=int)\n","    parser.add_argument(\"--max_length\", \"-l\", required=False, default=512, help=\"Max sequence length\", type=int)\n","    parser.add_argument(\"--seed\", \"-s\", required=False, default=42, help=\"Random seed\", type=int)\n","    parser.add_argument(\"--freeze_layers\", \"-f\", required=False, default=2, help=\"Number of transformer layers to freeze\", type=int)\n","    parser.add_argument(\"--use_custom_classifier\", \"-c\", required=False, default=True, help=\"Use custom classifier head\", type=bool)\n","\n","    args = parser.parse_args([])\n","    set_seed(args.seed)\n","\n","    # Map labels for Subtask B\n","    id2label = {0: \"human\", 1: \"chatGPT\", 2: \"cohere\", 3: \"davinci\", 4: \"bloomz\", 5: \"dolly\"}\n","    label2id = {v: k for k, v in id2label.items()}\n","\n","    # Device check\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Using device: {device}\")\n","\n","    # Validate file paths\n","    if not os.path.exists(args.train_file_path):\n","        raise FileNotFoundError(f\"Train file not found: {args.train_file_path}\")\n","    if not os.path.exists(args.test_file_path):\n","        raise FileNotFoundError(f\"Test file not found: {args.test_file_path}\")\n","\n","    # Prepare data\n","    train_df, valid_df, test_df = get_data(\n","        args.train_file_path, args.test_file_path, random_seed=args.seed\n","    )\n","\n","    print(f\"Training samples: {len(train_df)}\")\n","    print(f\"Validation samples: {len(valid_df)}\")\n","    print(f\"Test samples: {len(test_df)}\")\n","\n","    # Fine-tune with custom classifier and frozen layers\n","    ckpt_dir = os.path.join(args.output_dir, f\"{args.model.replace('/', '_')}_custom_classifier\")\n","    os.makedirs(ckpt_dir, exist_ok=True)\n","\n","    fine_tune(\n","        train_df=train_df,\n","        valid_df=valid_df,\n","        output_dir=ckpt_dir,\n","        id2label=id2label,\n","        label2id=label2id,\n","        model_name=args.model,\n","        device=device,\n","        num_epochs=args.num_epochs,\n","        per_device_batch=args.batch_size,\n","        gradient_accumulation_steps=args.accum_steps,\n","        max_length=args.max_length,\n","        freeze_layers=args.freeze_layers,\n","        use_custom_classifier=args.use_custom_classifier,\n","    )\n","\n","    # Test\n","    best_model_dir = os.path.join(ckpt_dir, \"best\")\n","    results, preds = test(\n","        test_df=test_df,\n","        model_path=best_model_dir,\n","        id2label=id2label,\n","        label2id=label2id,\n","        device=device,\n","        max_length=args.max_length,\n","        use_custom_classifier=args.use_custom_classifier,\n","    )\n","\n","    # Log metrics\n","    if results is not None:\n","        print(\"=== Classification Report ===\")\n","        for k, v in results.items():\n","            print(f\"{k}: {v}\")\n","\n","    # Save predictions\n","    pd.DataFrame({\"id\": test_df[\"id\"], \"label\": preds}).to_json(\n","        args.prediction_file_path, orient=\"records\", lines=True\n","    )\n","    print(f\"Done. Predictions saved to {args.prediction_file_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRaXiemjwOu9","outputId":"ebd306bb-6a25-4d31-9e05-7bac3ec80f78","executionInfo":{"status":"ok","timestamp":1751578337237,"user_tz":-180,"elapsed":1471770,"user":{"displayName":"Angel Kirilov","userId":"16100377354124465662"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: checkpoints/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/rng_state.pth (deflated 25%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/special_tokens_map.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/trainer_state.json (deflated 78%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/scheduler.pt (deflated 56%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/training_args.bin (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/tokenizer.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/optimizer.pt (deflated 8%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/model.safetensors (deflated 34%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/tokenizer_config.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/config.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/sentencepiece.bpe.model (deflated 49%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-3774/scaler.pt (deflated 60%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/rng_state.pth (deflated 25%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/special_tokens_map.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/trainer_state.json (deflated 81%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/scheduler.pt (deflated 55%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/training_args.bin (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/tokenizer.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/optimizer.pt (deflated 8%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/model.safetensors (deflated 34%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/tokenizer_config.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/config.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/sentencepiece.bpe.model (deflated 49%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-11322/scaler.pt (deflated 60%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/rng_state.pth (deflated 25%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/special_tokens_map.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/trainer_state.json (deflated 80%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/scheduler.pt (deflated 55%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/training_args.bin (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/tokenizer.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/optimizer.pt (deflated 8%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/model.safetensors (deflated 34%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/tokenizer_config.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/config.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/sentencepiece.bpe.model (deflated 49%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-7548/scaler.pt (deflated 60%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/rng_state.pth (deflated 25%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/special_tokens_map.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/trainer_state.json (deflated 81%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/scheduler.pt (deflated 55%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/training_args.bin (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/tokenizer.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/optimizer.pt (deflated 8%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/model.safetensors (deflated 34%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/tokenizer_config.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/config.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/sentencepiece.bpe.model (deflated 49%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-15096/scaler.pt (deflated 60%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/special_tokens_map.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/training_args.bin (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/tokenizer.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/model.safetensors (deflated 34%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/tokenizer_config.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/config.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/best/sentencepiece.bpe.model (deflated 49%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/logs/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/logs/events.out.tfevents.1751568958.1024e60b0168.227.0 (deflated 62%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/logs/events.out.tfevents.1751569788.1024e60b0168.227.2 (deflated 70%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/logs/events.out.tfevents.1751569450.1024e60b0168.227.1 (deflated 61%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/ (stored 0%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/rng_state.pth (deflated 25%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/special_tokens_map.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/trainer_state.json (deflated 82%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/scheduler.pt (deflated 55%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/training_args.bin (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/tokenizer.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/optimizer.pt (deflated 8%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/model.safetensors (deflated 34%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/tokenizer_config.json (deflated 76%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/config.json (deflated 52%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/sentencepiece.bpe.model (deflated 49%)\n","  adding: checkpoints/xlm-roberta-base_custom_classifier/checkpoint-18870/scaler.pt (deflated 60%)\n","  adding: subtaskB_predictions.jsonl (deflated 87%)\n"]}],"source":["!zip -r checkpoints1.zip checkpoints ./subtaskB_predictions.jsonl"]},{"cell_type":"code","source":[],"metadata":{"id":"o96drRm46zGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","files.download('checkpoints1.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"wgI9mlw3m1-9","executionInfo":{"status":"ok","timestamp":1751578351606,"user_tz":-180,"elapsed":17,"user":{"displayName":"Angel Kirilov","userId":"16100377354124465662"}},"outputId":"7700455f-d086-422e-99e7-8f20e8a8c34e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_34c008c8-b4a0-4b28-94cd-3d5dffa59dd9\", \"checkpoints1.zip\", 6782729227)"]},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMwozse7EvwR5Z6ORXtvYPw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b2d89dd4c0c149e9b4b7520563656550":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_068edb49a5fa46ae8c82f08408e603da","IPY_MODEL_042461ee284942b78ecedf7cbd9950fe","IPY_MODEL_379e866364044e36aedc49cd2e5db884"],"layout":"IPY_MODEL_1a97d49a7b734f21bb0581794569e70e"}},"068edb49a5fa46ae8c82f08408e603da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_100156ecaffc4346993de0b6dbbbfa86","placeholder":"​","style":"IPY_MODEL_f6aa16f3e3674e37a4eb010d90847828","value":"Map: 100%"}},"042461ee284942b78ecedf7cbd9950fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7cc87b0a4d941ec8e93f90e6172a606","max":60372,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3d72a33cb2240f1b1f52072422fb67c","value":60372}},"379e866364044e36aedc49cd2e5db884":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_386730f5721c4e4194808b195ef6ac65","placeholder":"​","style":"IPY_MODEL_727c74ab9daf430a80d42fc196a27f3b","value":" 60372/60372 [01:37&lt;00:00, 637.61 examples/s]"}},"1a97d49a7b734f21bb0581794569e70e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"100156ecaffc4346993de0b6dbbbfa86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6aa16f3e3674e37a4eb010d90847828":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7cc87b0a4d941ec8e93f90e6172a606":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3d72a33cb2240f1b1f52072422fb67c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"386730f5721c4e4194808b195ef6ac65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"727c74ab9daf430a80d42fc196a27f3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aef50d144c3d49af97f6eba427500a12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_950c6d960daa4272b559391eefaacbc3","IPY_MODEL_07c29ba0ff7f4587827c249f2dfbd635","IPY_MODEL_5190df24fcdc4232874a3a4114cdd73a"],"layout":"IPY_MODEL_257e65ae830f43b3aba876bd3a3da570"}},"950c6d960daa4272b559391eefaacbc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a62488b01d1041398361b8fbd131ac28","placeholder":"​","style":"IPY_MODEL_cee86f4c70f547cda2b4d0212d7fc1e5","value":"Map: 100%"}},"07c29ba0ff7f4587827c249f2dfbd635":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a46d2baef4bb4597a55a49f30e03a4fc","max":10655,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e85122f8cce466489e23602579c8286","value":10655}},"5190df24fcdc4232874a3a4114cdd73a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74e1c36f4e7493b936176949cac092c","placeholder":"​","style":"IPY_MODEL_dd026b5dfbef4c07b47ba9efafd696d1","value":" 10655/10655 [00:17&lt;00:00, 606.20 examples/s]"}},"257e65ae830f43b3aba876bd3a3da570":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a62488b01d1041398361b8fbd131ac28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cee86f4c70f547cda2b4d0212d7fc1e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a46d2baef4bb4597a55a49f30e03a4fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e85122f8cce466489e23602579c8286":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b74e1c36f4e7493b936176949cac092c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd026b5dfbef4c07b47ba9efafd696d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cfb353b11dd4bfe93e6204e17be5e75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed7db3bb80a045118d9bfe099bf22982","IPY_MODEL_fbc1f4cf70b44cb9ba1b34d6854aa7bb","IPY_MODEL_d46b5af37e7942e082e2fbe0118d160a"],"layout":"IPY_MODEL_ea8c5fc2dcce4eb39a1f34d2440e976c"}},"ed7db3bb80a045118d9bfe099bf22982":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9c0a5ef92f04245a445cf695c3262d6","placeholder":"​","style":"IPY_MODEL_8e650e49ef424cc8997a1def75e61064","value":"Downloading builder script: "}},"fbc1f4cf70b44cb9ba1b34d6854aa7bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f774e2cca2844ed3bde6e6536e8fe8a8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4f7ccae865a4b5ca2b4808b70fdfc1c","value":1}},"d46b5af37e7942e082e2fbe0118d160a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c4cda6112cc4206887e586ae828551b","placeholder":"​","style":"IPY_MODEL_0f116f156a4f4e98801a1a4d1c89d875","value":" 4.20k/? [00:00&lt;00:00, 201kB/s]"}},"ea8c5fc2dcce4eb39a1f34d2440e976c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9c0a5ef92f04245a445cf695c3262d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e650e49ef424cc8997a1def75e61064":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f774e2cca2844ed3bde6e6536e8fe8a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d4f7ccae865a4b5ca2b4808b70fdfc1c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c4cda6112cc4206887e586ae828551b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f116f156a4f4e98801a1a4d1c89d875":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05e39a0110884203b8d69f878a55370a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a102d587e4ab4e6281b6e909318af061","IPY_MODEL_65d01be201d04575a83280df71d98ff6","IPY_MODEL_e215d7b16d8345a58c153d605bb04467"],"layout":"IPY_MODEL_53fa0a7be32e44a28a3e262c84aae5e3"}},"a102d587e4ab4e6281b6e909318af061":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64cacccb03f34641a837395ac5647334","placeholder":"​","style":"IPY_MODEL_524501b2f23c4cf7b079eaa0598248aa","value":"Downloading builder script: "}},"65d01be201d04575a83280df71d98ff6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a92e5c9f40f84b4581913f900bdcea3c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0a81f971e494574a08f7244e48f9c39","value":1}},"e215d7b16d8345a58c153d605bb04467":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d16894fc717460d9e983db7d70561d7","placeholder":"​","style":"IPY_MODEL_b3d179eead9441c6a1a318e8f44deb8b","value":" 6.79k/? [00:00&lt;00:00, 474kB/s]"}},"53fa0a7be32e44a28a3e262c84aae5e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64cacccb03f34641a837395ac5647334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"524501b2f23c4cf7b079eaa0598248aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a92e5c9f40f84b4581913f900bdcea3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f0a81f971e494574a08f7244e48f9c39":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d16894fc717460d9e983db7d70561d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3d179eead9441c6a1a318e8f44deb8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07cd1102e81e499abbb339907b19fefd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_207424f0a86d4ae7af66d8eef02b3287","IPY_MODEL_abfc6339a3144d74bc012e44d7568205","IPY_MODEL_c5f798af68e94730a486220ffe51203a"],"layout":"IPY_MODEL_7ee391a293a349a9b8d8589b4660f982"}},"207424f0a86d4ae7af66d8eef02b3287":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29cb3b2cfa914f5399183f62331e372d","placeholder":"​","style":"IPY_MODEL_c20884050fdf40ea951e6548cf931440","value":"Map: 100%"}},"abfc6339a3144d74bc012e44d7568205":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d96e1ab45cd941dd826e967713660dae","max":18000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8a62e8e72b04f07aeb55f95e04a9b00","value":18000}},"c5f798af68e94730a486220ffe51203a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b57308f8370e4db4967d974bcef4c55d","placeholder":"​","style":"IPY_MODEL_67782482f5284cbe80a05c9e832da44d","value":" 18000/18000 [00:27&lt;00:00, 685.57 examples/s]"}},"7ee391a293a349a9b8d8589b4660f982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29cb3b2cfa914f5399183f62331e372d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c20884050fdf40ea951e6548cf931440":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d96e1ab45cd941dd826e967713660dae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8a62e8e72b04f07aeb55f95e04a9b00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b57308f8370e4db4967d974bcef4c55d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67782482f5284cbe80a05c9e832da44d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6364e5a4cbc64ae794b54d572e934689":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_903e68f3ea744fefa2352b3b5ac25a41","IPY_MODEL_14a5282ff77c41298149548c1528cdce","IPY_MODEL_4b768c23c8064b89801995b897991db5"],"layout":"IPY_MODEL_60eb848f970243a8bf2a5c3add4a4116"}},"903e68f3ea744fefa2352b3b5ac25a41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2483fb0927bc4471b7462cb9d3661ffd","placeholder":"​","style":"IPY_MODEL_d102f7de16174886a351a96a8b0e16b1","value":"Downloading builder script: "}},"14a5282ff77c41298149548c1528cdce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3b3b49c1c6845318e1b9fee1b0163d5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87ae35cdf89d4cb39fae63597dfad6cb","value":1}},"4b768c23c8064b89801995b897991db5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_679aff465a2a4801863e61e015df1e9c","placeholder":"​","style":"IPY_MODEL_14784ec1eb4e42a9b76dbd95315a42ac","value":" 5.24k/? [00:00&lt;00:00, 287kB/s]"}},"60eb848f970243a8bf2a5c3add4a4116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2483fb0927bc4471b7462cb9d3661ffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d102f7de16174886a351a96a8b0e16b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3b3b49c1c6845318e1b9fee1b0163d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"87ae35cdf89d4cb39fae63597dfad6cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"679aff465a2a4801863e61e015df1e9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14784ec1eb4e42a9b76dbd95315a42ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}